每一周，我们的同事都会向社区的成员们发布一些关于 Hugging Face 相关的更新，包括我们的产品和平台更新、社区活动、学习资源和内容更新、开源库和模型更新等，我们将其称之为「Hugging News」，本期 Hugging News 有哪些有趣的消息，快来看看吧！ 

## 重磅更新

### Transformers Agents 发布，通过自然语言控制超过十多万个 HF 模型！

@[](https://img-s1.andfun.cn/devrel/posts/2023/06/5c3e4b61fd156.jpg)

近期，我们发布了一个非常“大胆”的新特性: Transformers Agents，并加入到了 🤗Transformers 4.29 之后的版本中。它在 Transformers 的基础上提供了一个自然语言 API，来 “让 Transformers 可以做任何事情”。这其中有两个概念：一个是 Agent (代理)，另一个是 Tools (工具)，我们定义了一系列默认的工具，让代理去理解自然语言并使用这些工具。

https://hf.co/docs/transformers/transformers_agents

代理这里指的是大语言模型 (LLM)，你可以选择使用 OpenAI 的模型 (需要提供密钥)，或者开源的 StarCoder 和 OpenAssistant 的模型，我们会提示让代理去访问一组特定的工具。

工具指的是一个个单一的功能，我们定义了一系列工具，然后使用这些工具的描述来提示代理，并展示它将如何利用工具来执行查询中请求的内容。

![](https://img-s1.andfun.cn/devrel/posts/2023/06/539fab0653938.png)

我们在 transformers 中集成的工具包括：文档问答、文本问答、图片配文、图片问答、图像分割、语音转文本、文本转语音、零样本文本分类、文本摘要、翻译等。不过你也可以扩展这些一些与 transformers 无关的工具，比如从网络读取文本等。

https://hf.co/docs/transformers/custom_tools

## 辅助生成 (Assisted Generation) 发布: 将低延迟文本生成付诸实践，本地大语言模型助手不是梦！

大语言模型目前广受欢迎，但其响应速度的缓慢限制了其用户体验。对于需要快速反应的任务，人们通常使用规模较小的模型，但这会牺牲结果质量。文本生成的延迟主要来自于模型的前向传递步骤，即模型权重加载到设备计算核心的过程，我们的一篇博文介绍了一种新的解码方法，通过这种辅助生成方法，硬件中的延迟可以降低多达 10 倍。此外，还可以通过模型优化和输入批处理来改善模型前向传递的性能问题。

欢迎阅读中文博客内容 ([微信版](https://mp.weixin.qq.com/s/HSSgrJX-gNDs9VFLMKvVYQ)):
https://huggingface.co/blog/zh/assisted-generation

https://hf.co/spaces/joaogante/assisted_generation_demo

## 开源更新

### 开放的开源大语言模型排行榜

![](https://img-s1.andfun.cn/devrel/posts/2023/06/d7be083e3543d.png)

每周都有大量的大型语言模型 (LLM) 和各种聊天机器人发布，令人眼花缭乱～ 我们制作了一个开放的大语言模型排行版，主要目标是跟踪、排名和评估最新的大语言模型和聊天机器人，让所有人方便的观察到开源社区的进展和评估这些模型。这个排行榜有一个关键优势，社区中的任何成员都可以提交模型，并在 Hugging Face 的 GPU 集群上自动评估。

你可以在这里看到这个排行榜:
https://hf.co/spaces/HuggingFaceH4/open_llm_leaderboard

### Woodstock of AI 活动回顾视频 

回顾我们在 3 月底在旧金山举办的 AI 社区会议。
